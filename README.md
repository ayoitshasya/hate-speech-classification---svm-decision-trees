
1. Loaded and analyzed the dataset through exploratory data analysis (EDA).
2. After cleaning the data, split it into training and testing sets.
3. Tokenize the documents and transformed them into a matrix for vectorization.
4. Built vocabulary dictionaries and converted the data into a document-term matrix.
5. Using both a support vector classifier and a decision tree, we classified and predicted the test samples.
